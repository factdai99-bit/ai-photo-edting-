
import { GoogleGenAI, Modality } from "@google/genai";
import { fileToBase64 } from "../utils/fileUtils";
import { EditedImageResult } from "../types";

export async function editImageWithPrompt(imageFile: File, prompt: string): Promise<EditedImageResult> {
  if (!process.env.API_KEY) {
    throw new Error("API key not found. Please set the API_KEY environment variable.");
  }
  const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

  const base64ImageData = await fileToBase64(imageFile);

  const imagePart = {
    inlineData: {
      data: base64ImageData,
      mimeType: imageFile.type,
    },
  };

  const textPart = {
    text: prompt,
  };

  try {
    const response = await ai.models.generateContent({
      model: 'gemini-2.5-flash-image',
      contents: {
        parts: [imagePart, textPart],
      },
      config: {
        responseModalities: [Modality.IMAGE],
      },
    });

    for (const part of response.candidates?.[0]?.content?.parts || []) {
      if (part.inlineData) {
        return {
          base64Image: part.inlineData.data,
          mimeType: part.inlineData.mimeType,
        };
      }
    }
    
    throw new Error("No image was generated by the API.");
  } catch(error) {
    console.error("Gemini API call failed:", error);
    throw new Error("The AI model failed to process the request. Please try again with a different prompt or image.");
  }
}
